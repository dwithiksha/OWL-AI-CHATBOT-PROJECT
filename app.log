2025-08-23 16:59:03,070 - __main__ - INFO - Gemini AI initialized successfully
2025-08-23 16:59:03,124 - __main__ - INFO - Starting Owl AI Chatbot on port 5000
2025-08-23 16:59:03,125 - __main__ - INFO - Debug mode: False
2025-08-23 16:59:03,125 - __main__ - INFO - Gemini AI available: True
2025-08-23 16:59:03,148 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.50.171:5000
2025-08-23 16:59:03,149 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-08-23 16:59:12,550 - __main__ - INFO - Gemini AI initialized successfully
2025-08-23 16:59:12,615 - __main__ - INFO - Starting Owl AI Chatbot on port 5000
2025-08-23 16:59:12,616 - __main__ - INFO - Debug mode: False
2025-08-23 16:59:12,616 - __main__ - INFO - Gemini AI available: True
2025-08-23 16:59:12,634 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.50.171:5000
2025-08-23 16:59:12,635 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-08-23 16:59:18,422 - __main__ - ERROR - Unhandled exception: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-08-23 16:59:18,626 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\owl-ai-project\app.py", line 160, in home
    return render_template("index.html")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 150, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1084, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1013, in get_template
    return self._load_template(name, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 972, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 64, in get_source
    return self._get_source_fast(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 95, in _get_source_fast
    return loader.get_source(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 210, in get_source
    contents = f.read()
               ^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-08-23 16:59:18,725 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 16:59:18] "[35m[1mGET / HTTP/1.1[0m" 500 -
2025-08-23 16:59:18,948 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 16:59:18] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2025-08-23 16:59:27,521 - __main__ - ERROR - Unhandled exception: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-08-23 16:59:27,525 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\owl-ai-project\app.py", line 160, in home
    return render_template("index.html")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 150, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1084, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1013, in get_template
    return self._load_template(name, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 972, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 64, in get_source
    return self._get_source_fast(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 95, in _get_source_fast
    return loader.get_source(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 210, in get_source
    contents = f.read()
               ^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-08-23 16:59:27,528 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 16:59:27] "[35m[1mGET / HTTP/1.1[0m" 500 -
2025-08-23 16:59:38,864 - __main__ - INFO - Gemini AI initialized successfully
2025-08-23 16:59:38,932 - __main__ - INFO - Starting Owl AI Chatbot on port 5000
2025-08-23 16:59:38,933 - __main__ - INFO - Debug mode: False
2025-08-23 16:59:38,933 - __main__ - INFO - Gemini AI available: True
2025-08-23 16:59:38,964 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.50.171:5000
2025-08-23 16:59:38,966 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-08-23 16:59:46,192 - __main__ - ERROR - Unhandled exception: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-08-23 16:59:46,200 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\owl-ai-project\app.py", line 160, in home
    return render_template("index.html")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 150, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1084, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1013, in get_template
    return self._load_template(name, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 972, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 64, in get_source
    return self._get_source_fast(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 95, in _get_source_fast
    return loader.get_source(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 210, in get_source
    contents = f.read()
               ^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-08-23 16:59:46,203 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 16:59:46] "[35m[1mGET / HTTP/1.1[0m" 500 -
2025-08-23 17:00:36,119 - __main__ - ERROR - Unhandled exception: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-08-23 17:00:36,122 - __main__ - ERROR - Traceback (most recent call last):
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1484, in full_dispatch_request
    rv = self.dispatch_request()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\app.py", line 1469, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\owl-ai-project\app.py", line 160, in home
    return render_template("index.html")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 150, in render_template
    template = app.jinja_env.get_or_select_template(template_name_or_list)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1084, in get_or_select_template
    return self.get_template(template_name_or_list, parent, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 1013, in get_template
    return self._load_template(name, globals)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\environment.py", line 972, in _load_template
    template = self.loader.load(self, name, self.make_globals(globals))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 126, in load
    source, filename, uptodate = self.get_source(environment, name)
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 64, in get_source
    return self._get_source_fast(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\flask\templating.py", line 95, in _get_source_fast
    return loader.get_source(environment, template)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\lenovo\anaconda\jackson\Lib\site-packages\jinja2\loaders.py", line 210, in get_source
    contents = f.read()
               ^^^^^^^^
  File "<frozen codecs>", line 322, in decode
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte

2025-08-23 17:00:36,124 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:00:36] "[35m[1mGET / HTTP/1.1[0m" 500 -
2025-08-23 17:02:07,977 - __main__ - INFO - Gemini AI initialized successfully
2025-08-23 17:02:08,031 - __main__ - INFO - Starting Owl AI Chatbot on port 5000
2025-08-23 17:02:08,031 - __main__ - INFO - Debug mode: False
2025-08-23 17:02:08,031 - __main__ - INFO - Gemini AI available: True
2025-08-23 17:02:08,047 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.50.171:5000
2025-08-23 17:02:08,048 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-08-23 17:02:14,420 - __main__ - INFO - Gemini AI initialized successfully
2025-08-23 17:02:14,482 - __main__ - INFO - Starting Owl AI Chatbot on port 5000
2025-08-23 17:02:14,482 - __main__ - INFO - Debug mode: False
2025-08-23 17:02:14,483 - __main__ - INFO - Gemini AI available: True
2025-08-23 17:02:14,500 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.50.171:5000
2025-08-23 17:02:14,501 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-08-23 17:02:25,175 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:02:25] "GET / HTTP/1.1" 200 -
2025-08-23 17:02:25,530 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:02:25] "GET /static/style.css HTTP/1.1" 200 -
2025-08-23 17:02:33,828 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:02:33] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:02:39,590 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:02:39] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:02:42,980 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:02:42] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:08:19,811 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:08:19] "GET / HTTP/1.1" 200 -
2025-08-23 17:08:19,962 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:08:19] "GET /static/style.css HTTP/1.1" 200 -
2025-08-23 17:13:26,664 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:13:26] "GET / HTTP/1.1" 200 -
2025-08-23 17:13:26,810 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:13:26] "GET /static/style.css HTTP/1.1" 200 -
2025-08-23 17:13:35,693 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:13:35] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:13:56,877 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:13:56] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:14:27,574 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:14:27] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:14:39,465 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:14:39] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:18:06,365 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:18:06] "GET / HTTP/1.1" 200 -
2025-08-23 17:18:06,514 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:18:06] "GET /static/style.css HTTP/1.1" 200 -
2025-08-23 17:18:17,151 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:18:17] "POST /api/chat HTTP/1.1" 200 -
2025-08-23 17:23:09,181 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:23:09] "GET / HTTP/1.1" 200 -
2025-08-23 17:23:09,387 - werkzeug - INFO - 192.168.50.171 - - [23/Aug/2025 17:23:09] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
